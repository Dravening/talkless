# 运维调优操作梳理

### 系统查询操作

1.CoreDump文件存放位置

Core Dump文件是指程序运行时发生错误或崩溃时产生的一种错误报告文件。

以linux 5.4.224-1.el7.elrepo.x86_64 版本为例

```shell
[root@tcosmo-sh01 ~]# cat /proc/sys/kernel/core_pattern 
|/usr/lib/systemd/systemd-coredump %P %u %g %s %t %c %e
```

2.tcpDump

tcpdump是一个在Linux和Unix操作系统上的命令行网络分析工具。它可以嗅探并捕获网络数据包，并且能够分析和显示这些数据，以便于网络问题诊断和性能调优。

```
# 获取本机8021端口的tcp数据包
[root@xxx ~]# tcpdump -i team0 tcp port 8021 -A | grep -E "(GET|POST|HTTP\/1\.1|Content-Type)"
```

3.iotop / iostat

```
# iotop可以将进程按磁盘使用率排序
# iostat可以展示tps，这个指标可以一定程度上认为跟cpu上下文切换有关
[root@tcosmo-sh01 perf]# iostat
Linux 5.4.224-1.el7.elrepo.x86_64 (tcosmo-sh01)         08/04/2023      _x86_64_        (40 CPU)

avg-cpu:  %user   %nice %system %iowait  %steal   %idle
           3.56    0.04    1.37    0.01    0.00   95.02

Device:            tps    kB_read/s    kB_wrtn/s    kB_read    kB_wrtn
sda              36.21        52.45       370.10  896736664 6327330548
```



### perf工具使用

```
# 准备工具
yum install perf -y
yum install git
git clone https://github.com/brendangregg/FlameGraph.git
```

#### cpu

1.火焰图

```
# perf 采集指定pid的数据, 会在当前目录生成一个perf.data文件
perf record -F 99 -a -g -- sleep 60
perf record -F 99 -p <PID> -g -- sleep 60
```

```
# 生成火焰图
perf script --header > out.stacks
./FlameGraph/stackcollapse-perf.pl < out.stacks | ./FlameGraph/flamegraph.pl --hash > out.svg
# 简化
perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl > process.svg
```

2.上下文切换&调度器延时

```
[root@tcosmo-sh01 perf]# perf sched latency

 -------------------------------------------------------------------------------------
Task                  |   Runtime ms  | Switches | Avg delay ms    | Max delay ms    |
--------------------------------------------------------------------------------------
server:(34)           |     10.531 ms |       51 | avg:  50.890 ms | max: 499.838 ms |
operator:(29)         |     74.814 ms |       63 | avg:  33.244 ms | max: 191.127 ms |
alertmanager:(27)     |     72.509 ms |       46 | avg:  21.937 ms | max:  99.449 ms |
titanagent:(30)       |   1311.266 ms |       48 | avg:   4.796 ms | max:  51.464 ms |
iptables-save:(2)     |     16.756 ms |        2 | avg:   1.756 ms | max:   3.505 ms |
kubelet:(42)          |   1817.801 ms |      178 | avg:   0.113 ms | max:   3.681 ms |
containerd:(129)      |   4023.706 ms |      399 | avg:   0.078 ms | max:   7.323 ms |
flink-scheduler:(2)   |     80.551 ms |        3 | avg:   0.042 ms | max:   0.127 ms |
kube-proxy:(37)       |    269.239 ms |       72 | avg:   0.037 ms | max:   0.992 ms |
mongosh:(12)          |    917.941 ms |       13 | avg:   0.027 ms | max:   0.229 ms |
mongosh mongodb:(12)  |   5726.826 ms |       33 | avg:   0.021 ms | max:   0.337 ms |
```

其中Switches列代表了上下文切换的次数，delay代表了调度器延时时间（即在cpu队列中等待的时间）

3.PMC(硬件事件)

```
[root@tcosmo-sh01 perf]# perf stat -a -- sleep 10

 Performance counter stats for 'system wide':

        400,043.99 msec cpu-clock                 #   39.987 CPUs utilized          
           500,795      context-switches          #    0.001 M/sec                  
             9,443      cpu-migrations            #    0.024 K/sec                  
           276,254      page-faults               #    0.691 K/sec                  
    40,465,859,743      cycles                    #    0.101 GHz                    
    49,333,687,598      instructions              #    1.22  insn per cycle         
    10,471,620,081      branches                  #   26.176 M/sec                  
       181,383,338      branch-misses             #    1.73% of all branches        

      10.004372716 seconds time elapsed
```

其中'insn per cycle'为IPC（每周期指令数），可以衡量cpu的运行情况

#### memory

1.缺页（page-faults）火焰图

```
perf record -e page-faults -a -g -- sleep 10
perf script --header > out.stacks
./FlameGraph/stackcollapse-perf.pl < ./out.stacks | ./FlameGraph/flamegraph.pl --hash \
--bgcolor=green --count=pages --title="Page Fault Flame Graph" > page-faults.svg
```

2.内存分配（malloc）火焰图

```
[root@k8s-master perf]# perf record -e kmem:kmalloc -a -g -p 126509  -- sleep 10
Warning:
PID/TID switch overriding SYSTEM
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.557 MB perf.data (1352 samples) ]
```

```
# 先report看一看情况
[root@k8s-master perf]# perf report
```

```
[root@k8s-master perf]# perf script | FlameGraph/stackcollapse-perf.pl | FlameGraph/flamegraph.pl --bgcolor=green --title="kmalloc Flame Graph" > kmalloc.svg
```



### bpftrace工具使用

bpftrace是一个基于BPF的跟踪器，提供了一种高级编程语言来创建强大的单行命令和简短的脚本。

```
yum install sysstat -y
```

```
curl https://repos.baslab.org/rhel/7/bpftools/bpftools.repo --output /etc/yum.repos.d/bpftools.repo
yum install bpftrace bpftrace-tools bpftrace-doc bcc-static bcc-tools
```

1.按用户栈对PID为181的进程的libc malloc()请求量求和：

```
bpftrace -e 'uprobe:/lib/x86_64-linux-gnu/libc.so.6:malloc /pid == 181/ { @[ustack] = sum(arg0); }'
```

2.插入readline探针

```
# bpftrace -e 'uretprobe:/bin/bash:readline { printf("readline: \"%s\"\n", str(retval)); }'
Attaching 1 probe...
readline: "echo hi"
readline: "ls -l"
readline: "date"
readline: "uname -r"
```

3.malloc()字节火焰图

```
bpftrace -e 'u:/lib64/libc.so.6:malloc /pid == 361189/ { @[ustack] = hist(arg0); }' > out.stacks
git clone https://github.com/brendangregg/FlameGraph; cd FlameGraph
./stackcollapse-bpftrace.pl < ../out.stacks | ./flamegraph.pl --hash \--bgcolor=green --count=bytes --title="malloc() Bytes Flame Graph" > out.svg
```

> 注意：如果不知道/lib64/libc.so.6在哪，可以使用ldconfig -p | grep libc.so找到它
>         libc.so.6 (libc6,x86-64, OS ABI: Linux 2.6.32) => /lib64/libc.so.6



### Linux性能分析60秒

| 工具              | 检查                                       |
| ----------------- | ------------------------------------------ |
| uptime            | 负载1、5、15分钟的趋势                     |
| dmesg -T \| tail  | 包括OOM在内的内核错误                      |
| vmstat -SM 1      | 系统级统计总体情况                         |
| mpstat -P ALL 1   | 如果单个CPU繁忙，则线程扩展性很糟糕        |
| pidstat 1         | 每个进程的cpu使用情况，识别以外的CPU消费者 |
| iostat            | 磁盘IO统计                                 |
| free -m           | 内存使用情况                               |
| sar -n DEV 1      | 网络设备IO                                 |
| sar -n TCP,ETCP 1 | TCP统计：连接率、重传                      |
| top               | 常用概览                                   |



### CPU调优

cpu调优整体遵循先进程，后函数的原则。先考虑进程优化，后考虑函数优化（协程栈排错）。

#### 运维侧

运维侧关注cpu运行的整体情况，可以使用`perf stat -a -- sleep 10`命令进行概览

```
[root@tcosmo-sh01 perf]# perf stat -a -- sleep 10

 Performance counter stats for 'system wide':

        400,043.99 msec cpu-clock                 #   39.987 CPUs utilized ---(cpu个数)      
           500,795      context-switches          #    0.001 M/sec -----------(上下文切换)
             9,443      cpu-migrations            #    0.024 K/sec -----------(核间迁移)                 
           276,254      page-faults               #    0.691 K/sec -----------(缺页)
    40,465,859,743      cycles                    #    0.101 GHz -------------(cpu周期数)     
    49,333,687,598      instructions              #    1.22  insn per cycle --(每周期指令数)        
    10,471,620,081      branches                  #   26.176 M/sec -----------(分支预测次数)                  
       181,383,338      branch-misses             #    1.73% of all branches -(分支预测错误率)      

      10.004372716 seconds time elapsed
```

上述结果中，insn per cycle（IPC）为核心指标，服务器cpu调优的最终审核指标就是IPC是否有所提高。

如果出现IPC过低，刨除CPU硬件的问题，考虑从以下三点分析：

1. 服务器上运行了太多服务进程，导致CPU频繁切换上下文，降低了IPC。
2. 运行的服务包含大量依赖内存访问的指令，导致CPU等待内存的情况，降低了IPC。
3. 服务的代码存在未优化的锁竞争、等待同步等情况，导致CPU等待，降低IPC。

```
# 补充内容，cpu缓存未命中/CPU时钟周期数 得到cpu缓存未命中率
[root@tcosmo-sh01 ~]# perf stat -e cache-misses -e cycles -e sched:sched_switch -a -- sleep 10

 Performance counter stats for 'system wide':

       147,776,998      cache-misses ---------(CPU缓存未命中次数)                            
    39,148,222,520      cycles ---------------(CPU时钟周期数)                              
           472,432      sched:sched_switch ---(内核线程上下文切换次数)                                         

      10.003957619 seconds time elapsed
```

我们需要尽量降低<u>**单位时间上下文切换次数**</u>、<u>**降低缺页数**</u>、<u>**降低锁竞争**</u>

具体的做法就是减少进程抢占，并使cpu敏感的进程独占cpu。

```
# taskset设置cpu亲和性，并不意味着独占cpu
# taskset -pc <cpu_num_list> <pid>
[root@tcosmo-sh01 ~]# taskset -pc 0,1,2,3 1111
pid 1111's current affinity list: 0-39
pid 1111's new affinity list: 0-3
```

```
# cpuset可以实现独占cpu核心
# yum install libcgroup
[root@tcosmo-sh01 ~]# ls /sys/fs/cgroup/cpuset
cgroup.clone_children  cpuset.cpu_exclusive   cpuset.effective_mems  cpuset.memory_migrate           cpuset.memory_spread_page  cpuset.sched_load_balance        notify_on_release  tasks
cgroup.procs           cpuset.cpus            cpuset.mem_exclusive   cpuset.memory_pressure          cpuset.memory_spread_slab  cpuset.sched_relax_domain_level  release_agent
cgroup.sane_behavior   cpuset.effective_cpus  cpuset.mem_hardwall    cpuset.memory_pressure_enabled  cpuset.mems                kubepods.slice                   system.slice
```

```
# 在/sys/fs/cgroup/cpuset目录下创建一个自己的cpuset目录，并在其中的tasks中和cpus中各填入pid和cpu_id
[root@tcosmo-sh01 ~]# mkdir /sys/fs/cgroup/cpuset/mycpuset
[root@tcosmo-sh01 ~]# echo 1111 > /sys/fs/cgroup/cpuset/mycpuset/tasks
[root@tcosmo-sh01 ~]# echo 0 > /sys/fs/cgroup/cpuset/mycpuset/cpus
```

#### 研发侧

如果在运维侧已经尽量提升cpu的ipc了，那么接下来可以考虑研发侧优化自己的代码。

以go语言为例，可使用pprof和trace工具进行堆栈分析。

使用pprof工具执行<u>**cpu占用分析**</u>和<u>**协程栈分析**</u>。

cpu占用分析

```
# 收集cpu信息（）
curl -o cpu.out http://localhost:9981/debug/pprof/profile?seconds=60
# 在Web页面中进行解析
go tool pprof -http=localhost:8000 cpu.out
```

协程栈分析

```
# 主要用来查看协程在执行哪些函数，判断其健康状态（比如大多数携程都在干嘛？是否被阻塞？）
go tool pprof http://localhost:9981/debug/pprof/goroutine
(pprof) top
...
...
(pprof) tree
```



### 内存调优

内存的调优主要参考USE方法，保证其不要饱和即可，运维侧能做的工作不多。

其他的指标，如缺页(page-fault)和内存分配(malloc)更多的受进程影响，这部分需要研发调整自己的代码。

pprof堆内存分析

```
# 按占用内存的多少进行排序
go tool pprof http://localhost:9981/debug/pprof/heap
(pprof) top
```

此命令可分析出堆内存的占用情况，使用top可以分析出分配内存最多的函数来自哪里。

我曾用此方法定位到我自己写的time.tick内存泄漏问题（=。=）

```
# 按已经被分配的对象数量进行排序
(pprof) alloc_objects
(pprof) top
```



### 文件系统调优

